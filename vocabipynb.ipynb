{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfKo4r/B1NKL1Ia6BBkiNn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moondancer92/DoitBert/blob/main/vocabipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiFQsXjaQuj2",
        "outputId": "9103c720-4ecf-4d0b-e684-4f080e363cff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratsnlp\n"
      ],
      "metadata": {
        "id": "RH9_-Kd5HVyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f620145a-f071-4bdb-a51d-38eda5188211"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.53-py3-none-any.whl.metadata (741 bytes)\n",
            "Collecting pytorch-lightning==1.6.1 (from ratsnlp)\n",
            "  Downloading pytorch_lightning-1.6.1-py3-none-any.whl.metadata (33 kB)\n",
            "\u001b[33mWARNING: Ignoring version 1.6.1 of pytorch-lightning since it has invalid metadata:\n",
            "Requested pytorch-lightning==1.6.1 from https://files.pythonhosted.org/packages/77/5f/7f0b36c036334cb416230a7909b54c9a128a38623d2e18e87170e2055cd9/pytorch_lightning-1.6.1-py3-none-any.whl (from ratsnlp) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.8.*)\n",
            "           ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of ratsnlp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.52-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting pytorch-lightning==1.6.1 (from ratsnlp)\n",
            "  Using cached pytorch_lightning-1.6.1-py3-none-any.whl.metadata (33 kB)\n",
            "\u001b[33mWARNING: Ignoring version 1.6.1 of pytorch-lightning since it has invalid metadata:\n",
            "Requested pytorch-lightning==1.6.1 from https://files.pythonhosted.org/packages/77/5f/7f0b36c036334cb416230a7909b54c9a128a38623d2e18e87170e2055cd9/pytorch_lightning-1.6.1-py3-none-any.whl (from ratsnlp) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.8.*)\n",
            "           ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.51-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting pytorch-lightning==1.3.4 (from ratsnlp)\n",
            "  Downloading pytorch_lightning-1.3.4-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting transformers==4.10.0 (from ratsnlp)\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Korpora>=0.2.0 (from ratsnlp)\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ratsnlp) (3.1.0)\n",
            "Collecting flask-ngrok>=0.0.25 (from ratsnlp)\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting flask-cors>=3.0.10 (from ratsnlp)\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.5.1+cu124)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.67.1)\n",
            "Collecting PyYAML<=5.4.1,>=5.1 (from pytorch-lightning==1.3.4->ratsnlp)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Korpora\n",
        "from Korpora import Korpora\n",
        "nscm = Korpora.load(\"nsmc\", force_download=True)\n",
        "def wirte_lines(path,lines):\n",
        "  with open(path,'w', encoding='utf-8') as f:\n",
        "    for line in lines:\n",
        "      f.write(f'{line}\\n')\n",
        "\n",
        "wirte_lines(\"/content/train.txt\",nscm.train.get_all_texts())\n",
        "wirte_lines(\"/content/test.txt\",nscm.test.get_all_texts())"
      ],
      "metadata": {
        "id": "3LVfvdxOILrX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "outputId": "c0b3e2b8-de71-474e-9a23-4f6c1bd185c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Korpora\n",
            "  Using cached Korpora-0.2.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting dataclasses>=0.6 (from Korpora)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (2.32.3)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (2025.1.31)\n",
            "Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: dataclasses, Korpora\n",
            "Successfully installed Korpora-0.2.0 dataclasses-0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              },
              "id": "c3581e1797584d5e9e787bb07886fb44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : e9t@github\n",
            "    Repository : https://github.com/e9t/nsmc\n",
            "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
            "\n",
            "    Naver sentiment movie corpus v1.0\n",
            "    This is a movie review dataset in the Korean language.\n",
            "    Reviews were scraped from Naver Movies.\n",
            "\n",
            "    The dataset construction is based on the method noted in\n",
            "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
            "\n",
            "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nsmc] download ratings_train.txt: 14.6MB [00:00, 90.6MB/s]                           \n",
            "[nsmc] download ratings_test.txt: 4.90MB [00:00, 35.5MB/s]                           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"/gdrive/My Drive/nlpbook/bbpe\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "EEf6e7W_HOlU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "bytebpe_tokenizer = ByteLevelBPETokenizer()\n",
        "bytebpe_tokenizer.train(\n",
        "    files=[\"/content/train.txt\", \"/content/test.txt\"],\n",
        "    vocab_size=10000,\n",
        "    special_tokens=[\"[PAD]\"]\n",
        ")\n",
        "bytebpe_tokenizer.save_model(\"/gdrive/My Drive/nlpbook/bbpe\")"
      ],
      "metadata": {
        "id": "-O0MOAp5IfUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded9e7d9-6635-4b59-c26f-eb787f94370e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/My Drive/nlpbook/bbpe/vocab.json',\n",
              " '/gdrive/My Drive/nlpbook/bbpe/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}